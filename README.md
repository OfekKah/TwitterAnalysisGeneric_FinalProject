# Social Network Group Analysis Pipeline

This project is a Generic Social Network Group Analysis Pipeline implemented in Python. It allows for the analysis of group interactions on social networks, focusing on:
- Exploratory Data Analysis (EDA)
- Sentiment and Emotion Analysis
- Topic Modeling

The pipeline is designed to process and analyze data efficiently, offering a robust foundation for understanding group behavior, key themes, and sentiment distribution.

---

## Features

1. **EDA**:
   - **Analysis of Social Network Data**:
      - Accepts a database containing `authors` and `posts` tables.
      - Performs population-specific analysis if the `label` column exists in the `authors` table.
   - **Location Analysis**:
      - Extracts country information using the Llama model from the `location` column in the `authors` table.
2. **Sentiment, Emotion, and Hate Speech Analysis:**:
   - Performs analysis using three pre-trained deep learning models for `sentiment`, `emotion`, and `hate speech` detection.
   - Detects sentiment polarity (positive/negative/neutral) and emotion probabilities (e.g., joy, sadness, anger).
   - The output of running the model is saved in a dedicated directory.
   - Inside output directory, three CSV files contain the analysis results for each model: emotion_results.csv, sentiment_results.csv, and hate_speech_results.csv. These files include processed data such as authors, dates, content, and calculated statistics related to each respective analysis type.
   - The output directory contains three subdirectories: emotion_analysis_graphs, sentiment_analysis_graphs, and hate_speech_analysis_graphs, which store visual graphs generated from the analysis results.
3. **Topic Modeling**:
- Extracts the main themes from social network group posts using two techniques:
  
  - **BERTopic**:
    Generates interpretable topic clusters using UMAP and HDBSCAN. The script splits the dataset into time-based chunks and trains separate BERTopic models for each. It produces visualizations such as intertopic distance maps, topic over time plots, and stacked topic trends. Results are saved as CSVs and images inside `output_analysis/`.

  - **Latent Dirichlet Allocation (LDA)**:
    Applies a classic LDA pipeline with data cleaning, tokenization, stopword removal, and lemmatization. It automatically selects the optimal number of topics based on coherence score and exports word clouds, topic evolution plots, group-wise topic distributions, and an interactive pyLDAvis HTML. Outputs are saved under the `lda_output/` directory.

   - **Top2vec**:
   Top2Vec automatically identifies themes in text data by mapping words and documents into a shared vector space. The script uses this technique for tweet analysis, incorporating a specialized preprocessing pipeline for social media content. Outputs include topic summaries, word clouds, and visualizations of topic distribution and trends. Topic quality is assessed using coherence scores. Outputs are saved under the `Top2Vec_output/` directory.


---

## Requirements

To install all required dependencies, use the `requirements.txt` file:

```bash
pip install -r requirements.txt
```

---

## Usage

**Database Requirements**

The database must include the following tables and columns with the exact names:

- **Posts Table**:
  
   Columns:
     - `author`
     - `date`
     - `content`
- **Authors Table**:
  
   Columns:
     - `author_screen_name`
     - `friends_count`
     - `followers_count`
     - `statuses_count`
     - `location`
  
   Optional: `label` column for group-based analysis.

---

## Outputs

1. **EDA**:
   The following outputs are generated by the script:
   - **PNG Graphs**:
     
      **When analyzing more than one population, the following graphs are created and saved as PNG files:**
     
      For each population:
      - Population_X_followers_count_range
      - Population_X_friends_count_range
      - Population_X_statuses_count_range
      - Population_X_top_authors
      - Population_X_top_countries
      - Population_X_tweet_distribution
      
      Multi-Population Comparative Graphs:
      - Followers_Count_vs_Posts_Count_for_All_Groups
      - Followers_Count_Range_Merged
      - Friends_Count_Range_Merged
      - Posts_Count_Range_Merged
      - Tweet_Distribution_by_Month_for_All_Groups
    
       **When analyzing one population, the following graphs are created and saved as PNG files:**
     
      - All_Populations_followers_count_range
      - All_Populations_friends_count_range
      - All_Populations_statuses_count_range
      - All_Populations_top_authors
      - All_Populations_top_countries
      - All_Populations_tweet_distribution
      - Tweet_Distribution_by_Month_for_All_Populations
      - Followers_Count_vs_Posts_Count_for_All_Populations
   
   - **Summary Statistics**:
     
     A CSV file named summary_statistics.csv, containing aggregated statistics for the following columns:
      - `friends_count`
      - `followers_count`
      - `statuses_count`
    
     Additionally, the CSV includes a group column to indicate the population to which the statistics belong.
2. **Sentiment and Emotion analysis**

   - **Output Directory Structure**:
      The code creates a directory named `output_analysis` containing the following files and subdirectories:
      
      ```
      analysis_output/
      ├── emotion_analysis_graphs/
      │   └── trends_plot.png
      ├── emotion_results/
      │   └── emotion_results_partN.csv
      ├── hate_speech_analysis_graphs/
      │   └── trends_plot.png
      ├── hate_speech_results/
      │   └── hate_speech_results_partN.csv
      ├── sentiment_analysis_graphs/
      │   └── trends_plot.png
      ├── sentiment_results/
      │   └── sentiment_results_partN.csv
      ├── emotion_checkpoint.pkl
      ├── hate_speech_checkpoint.pkl
      └── sentiment_checkpoint.pkl
      ```
   
   
   - **Data Files**:
      - **Task-Specific Results (CSV Files)**:
      Each analysis task generates a tab-separated values (CSV) file:
      
      1. `emotion_results.csv`:
         - Contains emotion analysis scores for each tweet
         - Columns include: author, new_date, content, and emotion probabilities (joy, sadness, anger, surprise, etc.)
      
      2. `sentiment_results.csv`:
         - Contains sentiment analysis scores for each tweet
         - Columns include: author, new_date, content, and sentiment probabilities (positive, negative, neutral)
      
      3. `hate_speech_results.csv`:
         - Contains hate speech detection scores for each tweet
         - Columns include: author, new_date, content, and hate speech probabilities
      
      - **Checkpoint Files**:
         Each `.pkl` file stores the processing progress for its respective task:
         - `emotion_checkpoint.pkl`
         - `sentiment_checkpoint.pkl`
         - `hate_speech_checkpoint.pkl`
         
         These files allow the processing to resume from where it left off if interrupted.

   - **Visualization Outputs**:
      - **Trend Plots**:
      Each analysis task generates a set of trend plots saved in their respective directories:
      
      1. `emotion_analysis_graphs/trends_plot.png`:
         - Shows the evolution of different emotions over time
         - Each line represents a different social group (based on author labels)
         - Y-axis: Probability scores (0-1)
         - X-axis: Timeline (Year-Month)
      
      2. `sentiment_analysis_graphs/trends_plot.png`:
         - Displays sentiment trends over time
         - Separate lines for each social group
         - Y-axis: Sentiment probability scores
         - X-axis: Timeline (Year-Month)
      
      3. `hate_speech_analysis_graphs/trends_plot.png`:
         - Shows hate speech detection trends over time
         - Separate lines for different social groups
         - Y-axis: Probability scores
         - X-axis: Timeline (Year-Month)
  
      - **Data Processing Details**:
         - **Time Aggregation**:
            - Data is aggregated monthly
            - Each point in the trend plots represents the mean value for that month
            - The means are calculated in two steps:
              1. First calculates means per author per month
              2. Then calculates the mean across all authors in each social group
     
         - **Group Analysis**:
            - Results are separated by social groups defined in the authors table
            - Each group's trends are plotted with different colors for easy comparison
            - Legend identifies which line corresponds to which social group
  
      - **Reading the Visualizations**:
  
         - **Interpretation Guidelines**:
         1. Higher values indicate stronger presence of the analyzed attribute
         2. Trends can be compared across different social groups
         3. Sudden spikes or dips might indicate significant events or temporal patterns
         4. The confidence of predictions can be assessed by the probability scores
     
         - **Color Coding**:
            - Each social group is assigned a unique color in the plots
            - Consistent color scheme maintained across all visualizations for easy comparison
  
      - **Note on Data Processing**:
         - The analysis is performed in batches (default: 1000 tweets per batch)
         - Processing can be limited by setting max_batches (default: 10 batches)
         - Text is cleaned and preprocessed before analysis
         - Dates are standardized to ensure consistent temporal analysis
  
      - **Requirements for Viewing Outputs**:
         - CSV files can be opened with any spreadsheet software (Excel, Google Sheets, etc.)
         - PNG files can be viewed with any image viewer
         - Checkpoint files (.pkl) are binary files used by the program and not meant for direct viewing
      ---
3. **Topic modeling**:
   #### 3.1 BERTopic

   - **Output Directory Structure**:
      The code creates a directory named `bertopic_output` containing the following files and subdirectories:

      ```
      bertopic_output/
      ├── tweet_topic_mapping.csv
      ├── tweet_merged_topic_mapping.csv
      ├── tweet_topics_info.csv
      ├── tweet_topic_terms.csv
      ├── evaluation_scores.txt
      ├── tweet_bertopic_model/
      ├── topic_distribution.png
      ├── wordclouds_top5_topics.png
      ├── topic_similarity.html
      ├── topic_hierarchy.png
      ├── topics_over_time.html
      ├── stacked_area_topics_over_time_M.png
      ├── topics_label_distribution.png
      ├── sunburst_chart.png
      └── merged_topics_label_distribution.png
      ```


- **Data Files**:
  - `tweet_topic_mapping.csv`: Contains the original tweet-to-topic assignment.
  - `tweet_merged_topic_mapping.csv`: Same as above after merging semantically similar topics.
  - `tweet_topics_info.csv`: Metadata per topic (e.g., topic ID, count, name).
  - `tweet_topic_terms.csv`: Top keywords and weights per topic.
  - `evaluation_scores.txt`: Coherence and diversity evaluation metrics.
  - `tweet_bertopic_model/`: Saved BERTopic model.

- **Visualization Outputs**:
  - `topic_distribution.png`: Histogram showing the number of tweets per topic.
  - `wordclouds_top5_topics.png`: Word clouds of the top five topics.
  - `topic_similarity.html`: Intertopic distance visualization.
  - `topic_hierarchy.png`: Hierarchical cluster visualization.
  - `topics_over_time.html`: Interactive timeline of topic evolution.
  - `stacked_area_topics_over_time_M.png`: Stacked monthly topic trends.
  - `topics_label_distribution.png`: Normalized topic distribution per group.
  - `sunburst_chart.png`: Group participation per topic (donut style).
  - `merged_topics_label_distribution.png`: Distribution after merging.

- **Data Processing Notes**:
  - Tweets are cleaned and tokenized.
  - Embeddings are computed and clustered using UMAP and HDBSCAN.
  - Topics can be further refined by removing outliers and updating terms.


#### 3.2 LDA (Latent Dirichlet Allocation)

- **Output Directory Structure**:  
  The code creates a directory named `lda_output` containing the following files and subdirectories:
  

      lda_output/
      ├── lda_model/
      ├── lda_dictionary.csv
      ├── lda_topic_terms.csv
      ├── lda_dominant_topics.csv
      ├── lda_topic_info.csv
      ├── tweet_topic_label_mapping.csv
      ├── tweet_merged_topic_mapping.csv
      ├── pyldavis_intertopic_map.html
      ├── topic_wordclouds.png
      ├── topic_evaluation.png
      ├── stacked_area_topics_over_time_M.png
      ├── dominant_topic_distribution.png
      ├── topic_distribution_by_label.png
      ├── sunburst_chart.png
      └── sunburst_chart_merged.png

  
- **Data Files**:
  - `lda_model/`: Folder with the serialized LDA model.
  - `lda_dictionary.csv`: Dictionary of tokenized words with frequencies.
  - `lda_topic_terms.csv`: Top keywords per topic.
  - `lda_dominant_topics.csv`: Most likely topic for each tweet.
  - `lda_topic_info.csv`: Overview of topics with scores.
  - `tweet_topic_label_mapping.csv`: Mapping between tweets, topics, and labels.
  - `tweet_merged_topic_mapping.csv`: Topic mapping after grouping.

- **Visualization Outputs**:
  - `pyldavis_intertopic_map.html`: Interactive topic map using pyLDAvis.
  - `topic_wordclouds.png`: Word clouds for all topics.
  - `topic_evaluation.png`: Graph of coherence vs. topic number.
  - `stacked_area_topics_over_time_M.png`: Monthly topic trend (stacked).
  - `dominant_topic_distribution.png`: Distribution of dominant topics.
  - `topic_distribution_by_label.png`: Normalized topic distribution by label.
  - `sunburst_chart.png`: Group-based donut visualization of topic participation.
  - `sunburst_chart_merged.png`: Same as above after topic merging.

- **Data Processing Notes**:
  - Full preprocessing pipeline includes lemmatization and stopword removal.
  - Optimal topic count is selected based on coherence.
  - Group-level visualizations support comparative analysis.
#### 3.3 Top2Vec

-   **Output Directory Structure**:
    The code creates a directory named `Top2Vec_output` (configurable via `output_dir` in `top2vec_config.yaml`) containing the following files and subdirectories:

    ```text
    Top2Vec_output/
    ├── coherence_score.txt
    ├── coherence_vs_topn.png
    ├── topics_info.csv
    ├── topic_distribution.png
    ├── topic_similarity_matrix.png
    ├── topic_trend_over_time.png
    ├── tweets_with_topics.csv
    ├── wordcloud_topic_*.png
    └── best_top2vec_model/
    ```

-   **Data Files**:
    -   `best_top2vec_model/`: Folder with the trained Top2Vec model.
    -   `topics_info.csv`: Summary of identified topics, including their topic IDs and top 10 representative words.
    -   `tweets_with_topics.csv`: Original tweet data augmented with the assigned topic for each tweet.
    -   `coherence_score.txt`: Computed topic coherence score for the model.

-   **Visualization Outputs**:
    -   `wordcloud_topic_*.png`: Word clouds for the top 5 topics.
    -   `topic_distribution.png`: Plot showing the distribution of documents (tweets) across identified topics.
    -   `topic_similarity_matrix.png`: Heatmap representing the similarity between different topics.
    -   `coherence_vs_topn.png`: Plot visualizing the topic coherence score against different numbers of top-N words used to calculate coherence.
    -   `topic_trend_over_time.png`: Line plot visualizing the frequency of each topic over time.
    -   `stacked_topic_trends.png`: Stacked area chart of topic trends (generated by `save_topic_trend_plots` function).
    *(Note: `plot_stacked_topic_trends` and `save_topic_trend_plots` functions in the notebook seem to generate similar trend plots. I've listed both general types here for completeness based on the code's output.)*

-   **Data Processing Notes**:
    -   Tweets are cleaned and preprocessed using `pysentimiento.preprocessing` and custom regular expressions to remove URLs, emojis, hashtags, user mentions, numbers, and "RT" prefixes.
    -   Stop words are removed.
    -   Optimal topic count is automatically determined by Top2Vec based on dense areas of documents.
    -   Topic coherence is computed and plotted to assess topic quality.
---



## Authors
- Shay Herling 
- Ofek Kachlon
- Eden Naroditsky
- Shahar Revivo
