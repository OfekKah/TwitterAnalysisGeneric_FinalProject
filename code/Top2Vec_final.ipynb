{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd878813-2d24-4c0a-b87d-3c0f5e5352f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top2Vec Tweet Modeling Pipeline\n",
    "\n",
    "# 1. Setup and Imports\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from top2vec import Top2Vec\n",
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e456fd3-2ff1-4a40-8e75-f134de7bc977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.data.path.append(\"/sise/4-year-ise-proj/Ise4thYear/puzis-twitterAnalysisGeneric-2025/nltk_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1af2f17-ea61-48b7-8f8e-9c72065a1af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import logging\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from top2vec import Top2Vec\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def setup_logging(log_file):\n",
    "    logging.basicConfig(\n",
    "        filename=log_file,\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        filemode='w'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adb470c-b6d0-4ecc-9a9c-d3801dd53911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(path=\"top2vec_config.yaml\"):\n",
    "    with open(path, \"r\") as f:\n",
    "        return yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d5685-b983-4ab4-bc52-55318d0535be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_topic_summary_csv(topic_words, topic_nums, output_dir):\n",
    "    import pandas as pd\n",
    "    topic_df = pd.DataFrame({\n",
    "        \"topic_id\": topic_nums,\n",
    "        \"top_words\": [\", \".join(words[:10]) for words in topic_words]\n",
    "    })\n",
    "    topic_df.to_csv(os.path.join(output_dir, \"topics_info.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e3c9c3-4c86-4d27-aba5-197ac2d56d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_wordclouds(topic_words, word_scores, topic_nums, output_dir):\n",
    "    from wordcloud import WordCloud\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    for i, topic_id in enumerate(topic_nums[:5]):\n",
    "        words = topic_words[i][:30]\n",
    "        scores = word_scores[i][:30]\n",
    "        freq = dict(zip(words, scores))\n",
    "        wc = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(freq)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(wc, interpolation=\"bilinear\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Topic {topic_id}\")\n",
    "        plt.savefig(os.path.join(output_dir, f\"wordcloud_topic_{topic_id}.png\"))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e7cdf1-6df8-4c9a-aeb3-3770a9c9f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_topic_distribution_plot(topic_ids, topic_sizes, output_dir):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(topic_ids, topic_sizes)\n",
    "    plt.xlabel(\"Topic ID\")\n",
    "    plt.ylabel(\"Number of Documents\")\n",
    "    plt.title(\"Topic Distribution\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"topic_distribution.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93023a03-2b18-480f-9820-e0bc20f9cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_topic_similarity_plot(model, output_dir):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    try:\n",
    "        sim_matrix = getattr(model, \"topic_sim_matrix\", None)\n",
    "        if sim_matrix is not None:\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.imshow(sim_matrix, cmap='viridis')\n",
    "            plt.colorbar()\n",
    "            plt.title(\"Topic Similarity Matrix\")\n",
    "            plt.xlabel(\"Topic\")\n",
    "            plt.ylabel(\"Topic\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, \"topic_similarity_matrix.png\"))\n",
    "            plt.close()\n",
    "        else:\n",
    "            logging.warning(\"topic_sim_matrix not found in model.\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Could not generate topic similarity plot: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e3847-e89d-4db5-af49-f1a42fc3b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_topic_hierarchy(model, output_dir):\n",
    "    try:\n",
    "        model.hierarchical_topic_reduction(num_topics=10)\n",
    "        model.generate_topic_hierarchy(os.path.join(output_dir, \"topic_hierarchy.html\"))\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Could not generate topic hierarchy: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a715c14-8ff4-4916-89c3-9abb188f2c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stacked_topic_trends(df, topic_columns):\n",
    "    if not topic_columns:\n",
    "        print(\"⚠️ No topic columns found for plotting.\")\n",
    "        return\n",
    "\n",
    "    # Ensure the 'month' column exists and is in correct format\n",
    "    if \"month\" not in df.columns:\n",
    "        df['month'] = pd.to_datetime(df['created_at'], errors='coerce').dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "    # Filter to keep only numeric topic columns\n",
    "    numeric_topic_cols = [col for col in topic_columns if pd.api.types.is_numeric_dtype(df[col])]\n",
    "    if not numeric_topic_cols:\n",
    "        print(\"⚠️ No numeric topic columns found for plotting.\")\n",
    "        return\n",
    "\n",
    "    # Aggregate topic values by month\n",
    "    monthly_topics = df.groupby('month')[numeric_topic_cols].sum()\n",
    "\n",
    "    if monthly_topics.empty:\n",
    "        print(\"⚠️ monthly_topics is empty. Nothing to plot.\")\n",
    "        return\n",
    "\n",
    "    # Assign colors and plot\n",
    "    colors = cm.tab20(np.linspace(0, 1, monthly_topics.shape[1]))\n",
    "    monthly_topics.plot(kind='area', stacked=True, figsize=(14, 8), alpha=0.85, color=colors)\n",
    "\n",
    "    plt.title(\"Topic Trends Over Time\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Topic Activity\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f1dd4-420e-48c8-a204-215488699d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_topic_trend_plots(df, output_dir):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.cm as cm\n",
    "    import numpy as np\n",
    "\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')\n",
    "    df['month'] = df['created_at'].dt.to_period('M').dt.to_timestamp()\n",
    "    df = df.dropna(subset=[\"month\"])\n",
    "\n",
    "    # Line plot\n",
    "    grouped = df.groupby(['month', 'topic']).size().reset_index(name='count')\n",
    "    pivot = grouped.pivot(index='month', columns='topic', values='count').fillna(0)\n",
    "    pivot.plot(figsize=(14, 6))\n",
    "    plt.title(\"Topic Frequency Over Time\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Document Count\")\n",
    "    plt.legend(title=\"Topic\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"topic_trend_over_time.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Stacked area chart\n",
    "    topic_cols = [col for col in df.columns if col.startswith(\"topic_\")]\n",
    "    monthly = df.groupby(\"month\")[topic_cols].sum()\n",
    "    colors = cm.tab20(np.linspace(0, 1, len(topic_cols)))\n",
    "    monthly.plot(kind=\"area\", stacked=True, figsize=(14, 8), color=colors, alpha=0.85)\n",
    "    plt.title(\"Stacked Topic Trends\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Topic Counts\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"stacked_topic_trends.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be664785-11fa-48bc-876c-b45def4d2971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_outputs(model, df_posts, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    model.save(os.path.join(output_dir, \"best_top2vec_model\"))\n",
    "\n",
    "    topic_words, word_scores, topic_nums = model.get_topics()\n",
    "    topic_sizes, topic_ids = model.get_topic_sizes()\n",
    "    topic_cols = [col for col in df_posts.columns if col.startswith(\"topic_\")]\n",
    "\n",
    "    # ✅ Fix: Ensure 'month' exists\n",
    "    if \"month\" not in df_posts.columns:\n",
    "        df_posts[\"month\"] = pd.to_datetime(df_posts[\"created_at\"], errors=\"coerce\").dt.to_period(\"M\")\n",
    "\n",
    "    monthly = df_posts.groupby(\"month\")[topic_cols].sum()\n",
    "\n",
    "    save_topic_summary_csv(topic_words, topic_nums, output_dir)\n",
    "    save_wordclouds(topic_words, word_scores, topic_nums, output_dir)\n",
    "    save_topic_distribution_plot(topic_ids, topic_sizes, output_dir)\n",
    "    save_topic_similarity_plot(model, output_dir)\n",
    "    #save_topic_hierarchy(model, output_dir)\n",
    "    plot_stacked_topic_trends(df_posts, topic_cols)\n",
    "\n",
    "    df_posts[\"topic\"] = model.doc_top\n",
    "    df_posts.to_csv(os.path.join(output_dir, \"tweets_with_topics.csv\"), index=False)\n",
    "\n",
    "    for topic_id in set(model.doc_top):\n",
    "        df_posts[f'topic_{topic_id}'] = (model.doc_top == topic_id).astype(int)\n",
    "\n",
    "    save_topic_trend_plots(df_posts, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a682d0d-51b0-4317-8d89-e757839a5f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_top2vec_models(documents, param_grid):\n",
    "    results = []\n",
    "    for emb in param_grid[\"embedding_model\"]:\n",
    "        for speed in param_grid[\"speed\"]:\n",
    "            logging.info(f\"Training with embedding_model={emb}, speed={speed}\")\n",
    "            try:\n",
    "                model = Top2Vec(\n",
    "                    documents=documents,\n",
    "                    speed=speed,\n",
    "                    embedding_model=emb,\n",
    "                    keep_documents=True\n",
    "                )\n",
    "                results.append({\n",
    "                    \"model\": model,\n",
    "                    \"embedding_model\": emb,\n",
    "                    \"speed\": speed\n",
    "                })\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed config: {emb}, {speed} | Error: {e}\")\n",
    "\n",
    "    best = results[0]\n",
    "    logging.info(f\"Best config: {best['embedding_model']} + {best['speed']}\")\n",
    "    return best[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e555ac7-86fe-4ff6-a2e2-ab0e9e2a2d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# from nltk.tokenize import word_tokenize # Uncomment if you switch to word_tokenize\n",
    "# from nltk.tag import pos_tag # Uncomment if using pos_tag more directly\n",
    "\n",
    "# Ensure NLTK resources are downloaded and paths are set\n",
    "# (It's good practice to manage NLTK data path consistently)\n",
    "nltk_data_path = \"/sise/4-year-ise-proj/Ise4thYear/puzis-twitterAnalysisGeneric-2025/nltk_data\" # As in your original notebook\n",
    "nltk.data.path.append(nltk_data_path)\n",
    "\n",
    "try:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    nltk.download('stopwords', download_dir=nltk_data_path, quiet=True)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet.zip')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet', download_dir=nltk_data_path, quiet=True)\n",
    "try:\n",
    "    nltk.data.find('taggers/averaged_perceptron_tagger.zip') # For pos_tag\n",
    "except LookupError:\n",
    "    nltk.download('averaged_perceptron_tagger', download_dir=nltk_data_path, quiet=True)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba71b9e5-7750-422d-b5b9-842d5a92e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos_internal(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts.\n",
    "       Helper for lemmatization.\"\"\"\n",
    "    # Ensure word is not empty and is a string\n",
    "    if not word or not isinstance(word, str):\n",
    "        return nltk.corpus.wordnet.NOUN # Default to noun if word is problematic\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": nltk.corpus.wordnet.ADJ,\n",
    "                \"N\": nltk.corpus.wordnet.NOUN,\n",
    "                \"V\": nltk.corpus.wordnet.VERB,\n",
    "                \"R\": nltk.corpus.wordnet.ADV}\n",
    "    return tag_dict.get(tag, nltk.corpus.wordnet.NOUN) # Default to noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8882745-c289-48cf-89e5-88395025ee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_pipeline(text_series, pysentimiento_preprocess_tweet_func):\n",
    "    # 1. Pysentimiento preprocessing\n",
    "    # Pass the actual pysentimiento.preprocess_tweet function as an argument\n",
    "    logging.info(\"Applying pysentimiento.preprocess_tweet...\")\n",
    "    # Consider using shorten, e.g., preprocess_tweet(text, shorten=2)\n",
    "    # if you want to break up hashtags like #SomeTopic to \"some topic\"\n",
    "    processed_series = text_series.apply(lambda x: pysentimiento_preprocess_tweet_func(x))\n",
    "\n",
    "    # 2. Custom placeholder removal\n",
    "    logging.info(\"Removing placeholders...\")\n",
    "    placeholders_to_remove = [\n",
    "        r'\\burl\\b', r'\\bemoji\\b', r'\\bhashtag\\b', r'\\b@user\\b',\n",
    "        r'\\bnumber\\b', r'\\bhttps\\b',\n",
    "        r'\\ben\\b' # 'en' is debatable, could be a stopword or artifact.\n",
    "                 # If it's a common English word, general stopword removal will catch it.\n",
    "    ]\n",
    "    pattern = r'|'.join(placeholders_to_remove)\n",
    "    processed_series = processed_series.apply(lambda x: re.sub(pattern, '', x, flags=re.IGNORECASE))\n",
    "\n",
    "    # 3. Remove \"RT\" prefix\n",
    "    logging.info(\"Removing 'RT' prefix...\")\n",
    "    processed_series = processed_series.apply(lambda x: re.sub(r'^\\s*rt\\s+', '', x, flags=re.IGNORECASE).strip())\n",
    "\n",
    "\n",
    "    # 4. Optional: Lemmatization (decide if you want this)\n",
    "    # logging.info(\"Applying lemmatization (optional)...\")\n",
    "    # def lemmatize_internal(text):\n",
    "    #     tokens = text.split() # or use nltk.word_tokenize(text)\n",
    "    #     # Filter out empty strings that might result from previous steps before lemmatizing\n",
    "    #     lemmatized_tokens = [lemmatizer.lemmatize(w, get_wordnet_pos_internal(w)) for w in tokens if w]\n",
    "    #     return \" \".join(lemmatized_tokens)\n",
    "    # processed_series = processed_series.apply(lemmatize_internal)\n",
    "\n",
    "\n",
    "    # 5. Stop word removal\n",
    "    logging.info(\"Removing stopwords...\")\n",
    "    def remove_stopwords_internal(text):\n",
    "        words = text.split() # or use nltk.word_tokenize(text)\n",
    "        # Also remove very short words (e.g., single characters left after other cleaning)\n",
    "        # and ensure word is not empty before lowercasing\n",
    "        filtered_words = [word for word in words if word and word.lower() not in stop_words and len(word) > 1]\n",
    "        return \" \".join(filtered_words)\n",
    "    processed_series = processed_series.apply(remove_stopwords_internal)\n",
    "\n",
    "\n",
    "    # 6. Clean up extra spaces\n",
    "    logging.info(\"Cleaning up extra spaces...\")\n",
    "    processed_series = processed_series.apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n",
    "\n",
    "    return processed_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45faa94-618c-4273-baac-d316789befd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "def compute_topic_coherence(model, raw_documents, coherence='c_v', top_n_words=10):\n",
    "    \n",
    "    logging.info(\"Computing topic coherence...\")\n",
    "\n",
    "    topic_words, _, _ = model.get_topics()\n",
    "    topics_words = [[str(word) for word in topic[:top_n_words]] for topic in topic_words]\n",
    "\n",
    "    tokenized_texts = [simple_preprocess(doc) for doc in raw_documents]\n",
    "    dictionary = Dictionary(tokenized_texts)\n",
    "\n",
    "    # Filter out topics with all words missing from dictionary\n",
    "    valid_topics = []\n",
    "    for i, topic in enumerate(topics_words):\n",
    "        filtered = [word for word in topic if word in dictionary.token2id]\n",
    "        if len(filtered) == 0:\n",
    "            logging.warning(f\"Skipping topic {i} – no words found in dictionary.\")\n",
    "        else:\n",
    "            valid_topics.append(filtered)\n",
    "\n",
    "    if not valid_topics:\n",
    "        raise ValueError(\"No valid topics left after filtering out empty ones.\")\n",
    "\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=valid_topics,\n",
    "        texts=tokenized_texts,\n",
    "        dictionary=dictionary,\n",
    "        coherence=coherence\n",
    "    )\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    logging.info(f\"Topic Coherence Score ({coherence}): {coherence_score:.4f}\")\n",
    "    return coherence_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278a490a-f4ca-4332-91f2-ef975e6d6310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_coherence_vs_topn(model, raw_documents, topn_range=range(5, 21), coherence='c_v', output_path=None):\n",
    "    from gensim.models import CoherenceModel\n",
    "    from gensim.utils import simple_preprocess\n",
    "    from gensim.corpora import Dictionary\n",
    "\n",
    "    logging.info(\"Generating coherence plot...\")\n",
    "\n",
    "    tokenized_texts = [simple_preprocess(doc) for doc in raw_documents]\n",
    "    dictionary = Dictionary(tokenized_texts)\n",
    "    topic_words, _, _ = model.get_topics()\n",
    "\n",
    "    scores = []\n",
    "    valid_n = []\n",
    "\n",
    "    for topn in topn_range:\n",
    "        topics_words = [[str(word) for word in topic[:topn]] for topic in topic_words]\n",
    "\n",
    "        valid_topics = []\n",
    "        for topic in topics_words:\n",
    "            filtered = [word for word in topic if word in dictionary.token2id]\n",
    "            if filtered:\n",
    "                valid_topics.append(filtered)\n",
    "\n",
    "        if not valid_topics:\n",
    "            continue\n",
    "\n",
    "        cm = CoherenceModel(\n",
    "            topics=valid_topics,\n",
    "            texts=tokenized_texts,\n",
    "            dictionary=dictionary,\n",
    "            coherence=coherence\n",
    "        )\n",
    "        score = cm.get_coherence()\n",
    "        scores.append(score)\n",
    "        valid_n.append(topn)\n",
    "\n",
    "        logging.info(f\"Top {topn} words: Coherence = {score:.4f}\")\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(valid_n, scores, marker='o')\n",
    "    plt.title(f\"Topic Coherence vs. Top-N Words ({coherence})\")\n",
    "    plt.xlabel(\"Top-N Words per Topic\")\n",
    "    plt.ylabel(\"Coherence Score\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save if requested\n",
    "    if output_path:\n",
    "        plt.savefig(output_path)\n",
    "        logging.info(f\"Coherence plot saved to {output_path}\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c8cf6-1215-4ca7-88e8-f271a0b8f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load config and setup logging\n",
    "    config = load_config()\n",
    "    setup_logging(config[\"log_file\"]) # Make sure setup_logging is defined in an earlier cell\n",
    "    logging.info(\"Starting Top2Vec run.\")\n",
    "\n",
    "    # 1. Load all data from SQLite\n",
    "    conn = sqlite3.connect(\"New_Fire_DB.db\") # Ensure sqlite3 is imported\n",
    "    query = \"\"\"\n",
    "    SELECT tweet_id, user_screen_name AS author, full_text AS content, user_verified AS label, created_at\n",
    "    FROM posts\n",
    "    WHERE full_text IS NOT NULL;\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn) # Ensure pandas as pd is imported\n",
    "    conn.close()\n",
    "    logging.info(f\"Loaded {len(df)} tweets from database.\")\n",
    "\n",
    "    # 2. Clean and preprocess\n",
    "    df[\"content\"] = df[\"content\"].astype(str)\n",
    "    # The UserWarning about date parsing is from here. Specifying a format can help if known.\n",
    "    df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], errors=\"coerce\")\n",
    "\n",
    "    # Apply the preprocessing pipeline\n",
    "    # Pass the actual pysentimiento.preprocess_tweet function\n",
    "    df[\"clean_content\"] = preprocess_text_pipeline(df[\"content\"], preprocess_tweet)\n",
    "    logging.info(\"Completed text preprocessing pipeline.\")\n",
    "\n",
    "    # Filter out tweets that became empty or too short after cleaning\n",
    "    min_word_count = 3 # Example threshold\n",
    "    original_count = len(df)\n",
    "    df = df[df[\"clean_content\"].apply(lambda x: len(x.split()) >= min_word_count)]\n",
    "    # Also ensure content is not just whitespace\n",
    "    df = df[df[\"clean_content\"].str.strip().astype(bool)].reset_index(drop=True)\n",
    "    logging.info(f\"Filtered out {original_count - len(df)} tweets; {len(df)} remaining after length/empty check.\")\n",
    "\n",
    "\n",
    "    if df.empty:\n",
    "        logging.error(\"No documents available for training after preprocessing and filtering. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Apply max_docs *after* filtering\n",
    "    max_docs_to_use = config.get(\"max_docs\", len(df)) # Use all if max_docs not in config\n",
    "    df = df.head(max_docs_to_use)\n",
    "    logging.info(f\"Using {len(df)} documents for Top2Vec model training (max_docs).\")\n",
    "\n",
    "\n",
    "    documents = df[\"clean_content\"].tolist()\n",
    "\n",
    "    if not documents:\n",
    "        logging.error(f\"No documents available after applying max_docs. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Ensure Top2Vec and other model-related functions are defined/imported earlier\n",
    "    model = tune_top2vec_models(documents, config[\"param_grid\"])\n",
    "    save_model_outputs(model, df, config[\"output_dir\"])\n",
    "   \n",
    "\n",
    "    # Compute and log coherence score\n",
    "    coherence_score = compute_topic_coherence(model, df[\"content\"].tolist())\n",
    "    with open(os.path.join(config[\"output_dir\"], \"coherence_score.txt\"), \"w\") as f:\n",
    "        f.write(f\"Topic Coherence Score (c_v): {coherence_score:.4f}\")\n",
    "    # save coherence ploat\n",
    "    plot_coherence_vs_topn(\n",
    "    model,\n",
    "    raw_documents=df[\"content\"].tolist(),\n",
    "    output_path=os.path.join(config[\"output_dir\"], \"coherence_vs_topn.png\")\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    logging.info(\"Run complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db21eabb-da99-40c6-a4a1-b0129983b2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f69707-018c-418f-b5fa-86133990e5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
