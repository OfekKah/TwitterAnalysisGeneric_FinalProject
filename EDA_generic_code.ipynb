{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a336e111-0ebd-4574-bda1-33a02f0a622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import sqlite3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b44dbd3b-2afb-4013-b6fa-39298579b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_db(conn, table):\n",
    "    \"\"\"Retrieve all rows from a database table.\"\"\"\n",
    "    query = f\"SELECT * FROM {table}\"\n",
    "    return pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb7d137-a700-4de5-afb3-465d5b3b5da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_column(df, column):\n",
    "    \"\"\"Provide statistical description of a specified column.\"\"\"\n",
    "    return df[column].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c496920f-4d2c-4375-86a6-cc90184dc5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_counts(df, column, bins, labels):\n",
    "    \"\"\"Categorize a column into ranges and return value counts.\"\"\"\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    df = df.dropna(subset=[column])\n",
    "    return pd.cut(df[column], bins=bins, labels=labels).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cd77860-7677-4e56-aa35-034dfcdcc2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_chart(data, title, xlabel, ylabel, filename):\n",
    "    \"\"\"Plot a bar chart and save it to a file.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    data.plot(kind='bar', color='skyblue', alpha=0.7)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0a9ca52-0268-4aa4-824b-3d672921f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweets(df, column='date'):\n",
    "    \"\"\"Preprocess tweets to extract date and month.\"\"\"\n",
    "    df = df.copy()  # Create a copy to avoid warnings\n",
    "    df.loc[:, 'date_new'] = pd.to_datetime(df[column].apply(lambda d: d.split()[0]), errors='coerce')\n",
    "    df.loc[:, 'month'] = df['date_new'].dt.to_period('M')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fa54c77-f044-4af2-983b-97020a968e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tweet_distribution(df, title, filename, output_folder):\n",
    "    if os.path.commonpath([output_folder, filename]) == output_folder:\n",
    "        filename = os.path.relpath(filename, output_folder)\n",
    "    \n",
    "    tweets_per_month = df['month'].value_counts().sort_index()\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    sns.barplot(x=tweets_per_month.index.astype(str), y=tweets_per_month.values, palette=\"viridis\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Month', fontsize=12)\n",
    "    plt.ylabel('Number of Tweets', fontsize=12)\n",
    "    plt.xticks(rotation=65, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path = os.path.join(output_folder, filename)\n",
    "    print(f\"Saving graph to: {save_path}\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d582b14b-5b6c-4d21-96d9-05271015af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_group(data, group_name, output_folder, bins, labels, summary_file):\n",
    "    \"\"\"Analyze a single group and generate visualizations.\"\"\"\n",
    "    print(f\"Analyzing group: {group_name}\")\n",
    "    print(f\"Data size: {data.shape}\")\n",
    "\n",
    "    all_descriptions = []\n",
    "\n",
    "    for column in ['friends_count', 'followers_count', 'statuses_count']:\n",
    "        if column in data.columns:\n",
    "            print(f\"Missing values in {column}: {data[column].isnull().sum()}\")\n",
    "            description = describe_column(data, column).to_frame().T\n",
    "            description['group'] = group_name  \n",
    "            description['column'] = column  \n",
    "            all_descriptions.append(description)\n",
    "        else:\n",
    "            print(f\"Column {column} does not exist in the data.\")\n",
    "\n",
    "    if all_descriptions:\n",
    "        combined_descriptions = pd.concat(all_descriptions, ignore_index=True)\n",
    "        combined_descriptions = combined_descriptions.iloc[:,::-1]\n",
    "        if not os.path.exists(summary_file):  \n",
    "            combined_descriptions.to_csv(summary_file, index=False)\n",
    "        else:  \n",
    "            combined_descriptions.to_csv(summary_file, mode='a', index=False, header=False)\n",
    "        print(f\"Appended statistics for {group_name} to {summary_file}\")\n",
    "\n",
    "    for col, title in zip(['friends_count', 'followers_count', 'statuses_count'],\n",
    "                          [\"Friends Count\", \"Followers Count\", \"Posts Count\"]):\n",
    "        if col in data.columns:\n",
    "            categorized = categorize_counts(data, col, bins, labels)\n",
    "            chart_path = os.path.join(output_folder, f\"{group_name}_{col}_range.png\")\n",
    "            plot_bar_chart(categorized, f\"{group_name} by {title} Range\", \"Count Range\", \"Number of Individuals\", chart_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ad8fa82-14ec-4af0-9878-e3f40ba9ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_groups(groups_data, group_names, output_folder, bins, labels, summary_file):\n",
    "    \"\"\"Analyze multiple groups and generate visualizations.\"\"\"\n",
    "    for df, group_name in zip(groups_data, group_names):\n",
    "        analyze_group(df, group_name, output_folder, bins, labels, summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbcaa997-280b-4b63-be76-75d32ed706ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_friends_count_range(groups_data, group_names, output_folder, filename):\n",
    "    # Define the bins and labels\n",
    "    bins = [0, 50, 100, 200, 400, 700, 1000, 1500, float('inf')]\n",
    "    labels = ['<50', '50-100', '100-200', '200-400', '400-700', '700-1000', '1000-1500', '1500>']\n",
    "    # Initialize the dictionary\n",
    "    profession_counts = {}\n",
    "    for df, group_name in zip(groups_data, group_names):\n",
    "        # Convert 'friends_count' to numeric, coercing errors to NaN\n",
    "        df['friends_count'] = pd.to_numeric(df['friends_count'], errors='coerce')\n",
    "        # Drop rows with NaN values in 'friends_count'\n",
    "        df = df.dropna(subset=['friends_count'])\n",
    "        # Categorize friends count using consistent binning\n",
    "        df['friends_count_range'] = pd.cut(df['friends_count'], bins=bins, labels=labels)\n",
    "        # Count the number in each range\n",
    "        df_range_counts = df['friends_count_range'].value_counts().sort_index()\n",
    "        profession_counts[group_name] = df_range_counts\n",
    "        \n",
    "    # Combine the counts into a DataFrame\n",
    "    combined_counts = pd.DataFrame(profession_counts)\n",
    "    \n",
    "    # Plot the combined data\n",
    "    combined_counts.plot(kind='bar', figsize=(10, 6), color=['skyblue', 'orange'])\n",
    "    plt.title('Number of Friends Count Range for each populations')\n",
    "    plt.xlabel('Friends Count Range')\n",
    "    plt.ylabel('Number of Individuals')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.legend(title='Profession')\n",
    "    save_path = os.path.join(output_folder, filename)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "220f9f35-8586-41b0-8eb6-fb93d80864a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_followers_count_range(groups_data, group_names, output_folder, filename):\n",
    "    # Define the bins and labels\n",
    "    bins = [0, 50, 100, 200, 400, 700, 1000, 1500, float('inf')]\n",
    "    labels = ['<50', '50-100', '100-200', '200-400', '400-700', '700-1000', '1000-1500', '1500>']\n",
    "    # Initialize the dictionary\n",
    "    profession_counts = {}\n",
    "    for df, group_name in zip(groups_data, group_names):\n",
    "        # Convert 'followers_count' to numeric, coercing errors to NaN\n",
    "        df['followers_count'] = pd.to_numeric(df['followers_count'], errors='coerce')\n",
    "        # Drop rows with NaN values in 'followers_count'\n",
    "        df = df.dropna(subset=['followers_count'])\n",
    "        # Categorize friends count using consistent binning\n",
    "        df['followers_count_range'] = pd.cut(df['followers_count'], bins=bins, labels=labels)\n",
    "        # Count the number in each range\n",
    "        df_range_counts = df['followers_count_range'].value_counts().sort_index()\n",
    "        profession_counts[group_name] = df_range_counts\n",
    "        \n",
    "    # Combine the counts into a DataFrame\n",
    "    combined_counts = pd.DataFrame(profession_counts)\n",
    "    \n",
    "    # Plot the combined data\n",
    "    combined_counts.plot(kind='bar', figsize=(10, 6), color=['skyblue', 'orange'])\n",
    "    plt.title('Number of followers Count Range for each populations')\n",
    "    plt.xlabel('followers Count Range')\n",
    "    plt.ylabel('Number of Individuals')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.legend(title='Profession')\n",
    "    save_path = os.path.join(output_folder, filename)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b4dceae-17a8-4b4b-b61d-742f1c893b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_posts_count_range(groups_data, group_names, output_folder, filename):\n",
    "    # Define the bins and labels\n",
    "    bins = [0, 50, 100, 200, 400, 700, 1000, 1500, float('inf')]\n",
    "    labels = ['<50', '50-100', '100-200', '200-400', '400-700', '700-1000', '1000-1500', '1500>']\n",
    "    # Initialize the dictionary\n",
    "    profession_counts = {}\n",
    "    for df, group_name in zip(groups_data, group_names):\n",
    "        # Convert 'posts_count' to numeric, coercing errors to NaN\n",
    "        df['statuses_count'] = pd.to_numeric(df['statuses_count'], errors='coerce')\n",
    "        # Drop rows with NaN values in 'posts_count'\n",
    "        df = df.dropna(subset=['statuses_count'])\n",
    "        # Categorize posts count using consistent binning\n",
    "        df['posts_count_range'] = pd.cut(df['statuses_count'], bins=bins, labels=labels)\n",
    "        # Count the number in each range\n",
    "        df_range_counts = df['posts_count_range'].value_counts().sort_index()\n",
    "        profession_counts[group_name] = df_range_counts\n",
    "        \n",
    "    # Combine the counts into a DataFrame\n",
    "    combined_counts = pd.DataFrame(profession_counts)\n",
    "    \n",
    "    # Plot the combined data\n",
    "    combined_counts.plot(kind='bar', figsize=(10, 6), color=['skyblue', 'orange'])\n",
    "    plt.title('Number of posts Count Range for each populations')\n",
    "    plt.xlabel('posts Count Range')\n",
    "    plt.ylabel('Number of Individuals')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.legend(title='Profession')\n",
    "    save_path = os.path.join(output_folder, filename)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "749e2c28-7d55-4c64-9cb1-a9d1e7076738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_authors_by_tweet_count(df, group_name, output_folder):\n",
    "    \"\"\"Plot top authors by tweet count.\"\"\"\n",
    "    author_counts = df['author'].value_counts().head(10)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=author_counts.index, y=author_counts.values, palette='viridis')\n",
    "    plt.title(f\"Top Authors by Tweet Count in {group_name}\")\n",
    "    plt.xlabel(\"Author\")\n",
    "    plt.ylabel(\"Tweet Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder, f\"{group_name}_top_authors.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84fee980-7b07-4f52-b88b-397123cd324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_locations_by_count(df, group_name, output_folder):\n",
    "    \"\"\"\n",
    "    Plot top 10 countries by number of occurrences.\n",
    "    \"\"\"\n",
    "    # Count the occurrences of each country and get the top 10\n",
    "    # df = df[df['country'] != 'NaN']\n",
    "    country_counts = df['country'].value_counts().head(10)\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=country_counts.index, y=country_counts.values, palette='viridis')\n",
    "    plt.title(f\"Top 10 Countries by Count in {group_name}\")\n",
    "    plt.xlabel(\"Country\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(os.path.join(output_folder, f\"{group_name}_top_countries.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66e291b2-9462-48bc-8129-f202b4b8ce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_with_limits_multiple_groups(data_groups, labels, x_column, y_column, x_limit, y_limit, title, xlabel, ylabel, output_folder, sizes=None, colors=None, markers=None):\n",
    "    \"\"\"\n",
    "    Creates a scatter plot with custom settings for multiple datasets.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    if sizes is None:\n",
    "        sizes = [50] * len(data_groups)\n",
    "    if colors is None:\n",
    "        colors = ['blue', 'green', 'red', 'orange', 'purple'][:len(data_groups)]\n",
    "    if markers is None:\n",
    "        markers = ['o', '^', 's', 'p', '*'][:len(data_groups)]\n",
    "\n",
    "    for i, data in enumerate(data_groups):\n",
    "        plt.scatter(data[x_column], data[y_column], color=colors[i], edgecolor='black', label=labels[i], alpha=0.7, s=sizes[i], marker=markers[i])\n",
    "\n",
    "    plt.xlim(0, x_limit)\n",
    "    plt.ylim(0, y_limit)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.ylabel(ylabel, fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    file_path = os.path.join(output_folder, f\"{title.replace(' ', '_')}.png\") \n",
    "    plt.savefig(file_path)  \n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d447668e-11f5-4665-a5b8-35a5a9b0f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_groups_with_scatter(data_groups, group_names):\n",
    "    \"\"\"\n",
    "    Analyze multiple groups and include scatter plot for comparison.\n",
    "    \"\"\"\n",
    "    for df, group_name in zip(data_groups, group_names):\n",
    "        analyze_group(df, group_name)\n",
    "    \n",
    "    plot_scatter_with_limits_multiple_groups(\n",
    "        data_groups=data_groups,\n",
    "        labels=group_names,\n",
    "        x_column='followers_count',\n",
    "        y_column='statuses_count',\n",
    "        x_limit=20000,\n",
    "        y_limit=20000,\n",
    "        title='Followers vs Posts: Comparison between Groups',\n",
    "        xlabel='Followers Count',\n",
    "        ylabel='Posts Count'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e81ebe4-1cb1-48fa-bf0a-84189c44445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tweets_distribution_per_month_merged(dataframes, group_labels, title, output_folder):\n",
    "    \"\"\"Plot merged distribution of tweets per month for multiple groups.\"\"\"\n",
    "    combined_df = pd.concat(dataframes, keys=group_labels).reset_index(level=0).rename(columns={'level_0': 'Group'})\n",
    "    if 'date' not in combined_df.columns:\n",
    "        raise ValueError(\"Column 'date' is missing in the combined DataFrame.\")\n",
    "\n",
    "    combined_df.loc[:, 'month'] = pd.to_datetime(combined_df['craeted_at'].str.split().str[0], errors='coerce').dt.to_period('M')\n",
    "\n",
    "    tweets_per_month = combined_df.groupby(['month', 'Group']).size().unstack()\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    tweets_per_month.plot(kind='bar', stacked=False, figsize=(20, 8))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Number of Tweets')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Group', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path = os.path.join(output_folder, f\"{title.replace(' ', '_')}.png\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f09b5669-3b61-46e0-a70a-0781fbbf5a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_statistics_to_csv(data, group_name, summary_file):\n",
    "    \"\"\"Save statistics of a group's data to a single CSV file.\"\"\"\n",
    "    statistics = []\n",
    "    for column in ['friends_count', 'followers_count', 'statuses_count']:\n",
    "        if column in data.columns:\n",
    "            description = describe_column(data, column).to_frame().T\n",
    "            description['group'] = group_name  \n",
    "            description['column'] = column  \n",
    "            statistics.append(description)\n",
    "\n",
    "    if statistics:\n",
    "        combined_statistics = pd.concat(statistics, ignore_index=True)\n",
    "        combined_statistics = combined_statistics.iloc[:,::-1]\n",
    "        if not os.path.exists(summary_file):  \n",
    "            combined_statistics.to_csv(summary_file, index=False)\n",
    "        else:  \n",
    "            combined_statistics.to_csv(summary_file, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4df8c738-9498-40b4-976c-0693c0a53b70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (1.26.3)\n",
      "Requirement already satisfied: pandas in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2.1.4)\n",
      "Requirement already satisfied: seaborn in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (0.12.2)\n",
      "Requirement already satisfied: torch in /home/shayher/.local/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (2.5.1+cpu)\n",
      "Requirement already satisfied: accelerate==1.2.1 in /home/shayher/.local/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (1.2.1)\n",
      "Requirement already satisfied: bitsandbytes==0.45.0 in /home/shayher/.local/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (0.45.0)\n",
      "Requirement already satisfied: transformers==4.47.1 in /home/shayher/.local/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (4.47.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from accelerate==1.2.1->-r requirements.txt (line 5)) (23.1)\n",
      "Requirement already satisfied: psutil in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from accelerate==1.2.1->-r requirements.txt (line 5)) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from accelerate==1.2.1->-r requirements.txt (line 5)) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/shayher/.local/lib/python3.11/site-packages (from accelerate==1.2.1->-r requirements.txt (line 5)) (0.27.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/shayher/.local/lib/python3.11/site-packages (from accelerate==1.2.1->-r requirements.txt (line 5)) (0.4.5)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from bitsandbytes==0.45.0->-r requirements.txt (line 6)) (4.9.0)\n",
      "Requirement already satisfied: filelock in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from transformers==4.47.1->-r requirements.txt (line 7)) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from transformers==4.47.1->-r requirements.txt (line 7)) (2023.10.3)\n",
      "Requirement already satisfied: requests in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from transformers==4.47.1->-r requirements.txt (line 7)) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/shayher/.local/lib/python3.11/site-packages (from transformers==4.47.1->-r requirements.txt (line 7)) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from transformers==4.47.1->-r requirements.txt (line 7)) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 2)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from seaborn->-r requirements.txt (line 3)) (3.8.0)\n",
      "Requirement already satisfied: networkx in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/shayher/.local/lib/python3.11/site-packages (from torch->-r requirements.txt (line 4)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn->-r requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn->-r requirements.txt (line 3)) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn->-r requirements.txt (line 3)) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn->-r requirements.txt (line 3)) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn->-r requirements.txt (line 3)) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 4)) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from requests->transformers==4.47.1->-r requirements.txt (line 7)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from requests->transformers==4.47.1->-r requirements.txt (line 7)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from requests->transformers==4.47.1->-r requirements.txt (line 7)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /storage/modules/packages/anaconda/lib/python3.11/site-packages (from requests->transformers==4.47.1->-r requirements.txt (line 7)) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "503500b7-cdd2-4011-ba4c-d17c223038ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing group: All_Populations\n",
      "Data size: (175, 33)\n",
      "Missing values in friends_count: 0\n",
      "Missing values in followers_count: 0\n",
      "Missing values in statuses_count: 0\n",
      "Appended statistics for All_Populations to output/summary_statistics.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3824438/1724974311.py:7: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=tweets_per_month.index.astype(str), y=tweets_per_month.values, palette=\"viridis\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving graph to: output/All_Populations_tweet_distribution.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3824438/499599832.py:6: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=author_counts.index, y=author_counts.values, palette='viridis')\n",
      "/tmp/ipykernel_3824438/1801982510.py:11: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=country_counts.index, y=country_counts.values, palette='viridis')\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def main():\n",
    "    output_folder = 'output'\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    summary_file = os.path.join(output_folder, 'summary_statistics.csv')\n",
    "    BINS = [0, 100, 500, 1000, 5000, 10000, 20000]\n",
    "    LABELS = ['0-100', '101-500', '501-1000', '1001-5000', '5001-10000', '10001-20000']\n",
    "\n",
    "    db_path = '53k_individual_hcps_70_percent_confidence_tweets_2019_2022.db'\n",
    "    conn = sqlite3.connect(db_path)\n",
    "\n",
    "    authors_table = 'authors'\n",
    "    posts_table = 'posts'\n",
    "\n",
    "    try:\n",
    "        author_columns = pd.read_sql(f\"PRAGMA table_info({authors_table})\", conn)['name'].tolist()\n",
    "        if 'label' in author_columns:\n",
    "            all_author_data = read_db(conn, authors_table)\n",
    "            unique_labels = all_author_data['label'].unique()\n",
    "\n",
    "            group_data = []\n",
    "            group_names = []\n",
    "\n",
    "            for label in unique_labels:\n",
    "                # Skip invalid labels (None or NaN)\n",
    "                if label is None or pd.isna(label):\n",
    "                    print(\"Skipping invalid group label: None or NaN\")\n",
    "                    continue\n",
    "\n",
    "                group = all_author_data.query(f\"label == '{label}'\")\n",
    "                \n",
    "                # Skip empty groups\n",
    "                if group.empty:\n",
    "                    print(f\"Skipping empty group for label: {label}\")\n",
    "                    continue\n",
    "\n",
    "                group_data.append(group)\n",
    "                group_names.append(label)\n",
    "\n",
    "            analyze_groups(group_data, group_names, output_folder, BINS, LABELS, summary_file)\n",
    "\n",
    "            posts_data = read_db(conn, posts_table)\n",
    "            \n",
    "\n",
    "            # Process and visualize each group's tweet distribution\n",
    "            for group, name in zip(group_data, group_names):\n",
    "                group_posts = posts_data[posts_data['author'].isin(group['author_screen_name'].unique())].copy()\n",
    "                group_posts['date_new'] = pd.to_datetime(\n",
    "                    group_posts['date'].apply(lambda d: d.split()[0]),\n",
    "                    errors='coerce'\n",
    "                )\n",
    "                group_posts['month'] = group_posts['date_new'].dt.to_period('M')\n",
    "\n",
    "                distribution_path = os.path.join(output_folder, f\"{name}_tweet_distribution.png\")\n",
    "                plot_tweet_distribution(\n",
    "                    group_posts, \n",
    "                    f\"{name} Tweet Distribution\", \n",
    "                    f\"{name}_tweet_distribution.png\", \n",
    "                    output_folder\n",
    "                )\n",
    "                plot_top_authors_by_tweet_count(group_posts, name, output_folder)\n",
    "                \n",
    "\n",
    "            plot_friends_count_range(group_data, group_names, output_folder, f\"Friends_Count_Range_Merged.png\")\n",
    "            plot_followers_count_range(group_data, group_names, output_folder, f\"Followers_Count_Range_Merged.png\")\n",
    "            plot_posts_count_range(group_data, group_names, output_folder, f\"Posts_Count_Range_Merged.png\")\n",
    "\n",
    "            # Combined distribution plot\n",
    "            plot_tweets_distribution_per_month_merged(\n",
    "                [posts_data[posts_data['author'].isin(group['author_screen_name'].unique())] for group in group_data],\n",
    "                group_names,\n",
    "                \"Tweet Distribution by Month for All Groups\",\n",
    "                output_folder\n",
    "            )\n",
    "\n",
    "            # Combined scatter plot\n",
    "            plot_scatter_with_limits_multiple_groups(\n",
    "                group_data,\n",
    "                group_names,\n",
    "                x_column='followers_count',\n",
    "                y_column='statuses_count',\n",
    "                x_limit=20000,\n",
    "                y_limit=20000,\n",
    "                title=\"Followers Count vs. Posts Count for All Groups\",\n",
    "                xlabel='Followers Count',\n",
    "                ylabel='Post Count',\n",
    "                output_folder=output_folder\n",
    "            )\n",
    "        else:\n",
    "            all_data = read_db(conn, authors_table)\n",
    "            \n",
    "            analyze_group(all_data, \"All_Populations\", output_folder, BINS, LABELS, summary_file)\n",
    "\n",
    "            # Plot tweet distribution\n",
    "            posts_data = read_db(conn, posts_table)\n",
    "            posts_data['date_new'] = pd.to_datetime(posts_data['date'].apply(lambda d: d.split()[0]), errors='coerce')\n",
    "            posts_data['month'] = posts_data['date_new'].dt.to_period('M')\n",
    "            plot_tweet_distribution(posts_data, \"All Populations Tweet Distribution\", \"All_Populations_tweet_distribution.png\", output_folder)\n",
    "            plot_top_authors_by_tweet_count(posts_data, \"All_Populations\", output_folder)\n",
    "            \n",
    "        \n",
    "        # # Define the path to your Python script\n",
    "        # script_path = \"Llama_3_Hugging_Face_Cleaned.py\"\n",
    "        \n",
    "        # Run the Python script with the db_path as an argument\n",
    "        # subprocess.run([\"python\", script_path, db_path], capture_output=True, text=True)\n",
    "        # result = subprocess.run([\"python\", script_path, db_path], capture_output=True, text=True)\n",
    "\n",
    "        # # Print or log the captured output\n",
    "        # print(\"Subprocess Output:\", result.stdout)\n",
    "        # print(\"Subprocess Error Output:\", result.stderr)\n",
    "\n",
    "        if 'label' in author_columns:\n",
    "            all_author_data = read_db(conn, authors_table)\n",
    "            unique_labels = all_author_data['label'].unique()\n",
    "            group_data = []\n",
    "            group_names = []\n",
    "            for label in unique_labels:\n",
    "                # Skip invalid labels (None or NaN)\n",
    "                if label is None or pd.isna(label):\n",
    "                    print(\"Skipping invalid group label: None or NaN\")\n",
    "                    continue\n",
    "                group = all_author_data.query(f\"label == '{label}'\")\n",
    "                # Skip empty groups\n",
    "                if group.empty:\n",
    "                    print(f\"Skipping empty group for label: {label}\")\n",
    "                    continue\n",
    "                group_data.append(group)\n",
    "                group_names.append(label)\n",
    "\n",
    "            # Process and visualize each group's tweet distribution\n",
    "            for group, name in zip(group_data, group_names):\n",
    "                plot_top_locations_by_count(group, name, output_folder)\n",
    "        else:\n",
    "            plot_top_locations_by_count(all_data, \"All_Populations\", output_folder)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f18ff2-4ed8-4f8e-8cdd-114948c939ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0189a2-758e-40cb-a0e2-7d0410c1f2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
